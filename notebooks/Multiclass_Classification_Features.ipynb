{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification with Feature Extraction\n",
    "\n",
    "This notebook demonstrates **feature extraction** for 7-class skin lesion classification:\n",
    "- **HOG Features**: Handcrafted gradient-based features\n",
    "- **VGG16 Features**: Deep learning transfer learning\n",
    "- **Expected improvement**: Better accuracy and faster training\n",
    "\n",
    "**Classes (7):**\n",
    "- nv: Melanocytic nevi (~67%)\n",
    "- mel: Melanoma (~11%)\n",
    "- bkl: Benign keratosis-like lesions (~11%)\n",
    "- bcc: Basal cell carcinoma (~5%)\n",
    "- akiec: Actinic keratoses (~3%)\n",
    "- vasc: Vascular lesions (~1%)\n",
    "- df: Dermatofibroma (~1%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    top_k_accuracy_score\n",
    ")\n",
    "\n",
    "# Import preprocessing utilities\n",
    "from image_loader import load_images_from_metadata\n",
    "from preprocessing import prepare_images_with_feature_extraction, DX_DICT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print('✓ Libraries imported successfully!')\n",
    "print('✓ Using enhanced preprocessing with feature extraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration: Choose Feature Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION: Choose your feature extraction method\n",
    "# ============================================================\n",
    "\n",
    "# Option 1: HOG Features (Fast, no TensorFlow)\n",
    "FEATURE_METHOD = 'hog'\n",
    "FEATURE_PARAMS = {\n",
    "    'target_size': (128, 128),\n",
    "    'pixels_per_cell': (16, 16),\n",
    "    'cells_per_block': (2, 2)\n",
    "}\n",
    "\n",
    "# Option 2: VGG16 Features (Best accuracy, requires TensorFlow)\n",
    "# FEATURE_METHOD = 'vgg16'\n",
    "# FEATURE_PARAMS = {'pooling': 'avg'}\n",
    "\n",
    "# Option 3: ResNet50 Features (Deep features, requires TensorFlow)\n",
    "# FEATURE_METHOD = 'resnet50'\n",
    "# FEATURE_PARAMS = {'pooling': 'avg'}\n",
    "\n",
    "print(f'Feature Extraction Method: {FEATURE_METHOD.upper()}')\n",
    "print(f'Parameters: {FEATURE_PARAMS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_path = '../data/HAM10000_metadata.csv'\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f'Metadata loaded: {df.shape[0]} samples')\n",
    "print(f'\\nDiagnosis types:')\n",
    "print(df['dx'].value_counts())\n",
    "print(f'\\nDiagnosis names:')\n",
    "for code, name in DX_DICT.items():\n",
    "    count = (df['dx'] == code).sum()\n",
    "    print(f'  {code}: {name} ({count} samples, {count/len(df)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Count plot\n",
    "plt.subplot(1, 2, 1)\n",
    "df['dx'].value_counts().plot(kind='bar', color='steelblue')\n",
    "plt.title('Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Diagnosis', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "plt.subplot(1, 2, 2)\n",
    "df['dx'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n⚠ Note: Imbalanced dataset - nv (67%) dominates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "print('Loading images... This may take several minutes.')\n",
    "print('=' * 60)\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "images, loaded_image_ids = load_images_from_metadata(\n",
    "    df,\n",
    "    base_path='../data',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    normalize=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f'\\nLoaded images shape: {images.shape}')\n",
    "print(f'Memory usage: {images.nbytes / (1024**3):.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "fig, axes = plt.subplots(2, 7, figsize=(18, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (code, name) in enumerate(DX_DICT.items()):\n",
    "    # Find first image of this class\n",
    "    idx = df[df['dx'] == code].index[0]\n",
    "    axes[i].imshow(images[idx])\n",
    "    axes[i].set_title(f'{code}\\n{name.split()[0]}', fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Show second example\n",
    "    if len(df[df['dx'] == code]) > 1:\n",
    "        idx2 = df[df['dx'] == code].index[1]\n",
    "        axes[i+7].imshow(images[idx2])\n",
    "        axes[i+7].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Class (7 Types)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "df_filtered = df[df['image_id'].isin(loaded_image_ids)].reset_index(drop=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_filtered['dx'])\n",
    "\n",
    "print('Label Encoding:')\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    count = (y_encoded == i).sum()\n",
    "    print(f'  {i}: {class_name} - {DX_DICT[class_name]} ({count} samples)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print('Train-Test Split:')\n",
    "print(f'Training: {X_train.shape}')\n",
    "print(f'Testing: {X_test.shape}')\n",
    "print(f'\\nTraining class distribution:')\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    class_name = label_encoder.classes_[label]\n",
    "    print(f'  {label} ({class_name}): {count} ({count/len(y_train)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "print(f'Extracting {FEATURE_METHOD.upper()} features...')\n",
    "print('=' * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "prep_data = prepare_images_with_feature_extraction(\n",
    "    X_train, X_test,\n",
    "    method=FEATURE_METHOD,\n",
    "    use_pca=False,  # Feature extraction already reduces dimensions\n",
    "    **FEATURE_PARAMS\n",
    ")\n",
    "\n",
    "preprocessing_time = time.time() - start_time\n",
    "\n",
    "print(f'\\n✓ Feature extraction complete! Time: {preprocessing_time:.2f} seconds')\n",
    "print(f'\\nFeature Summary:')\n",
    "print(f'  Method: {FEATURE_METHOD.upper()}')\n",
    "print(f'  Training features: {prep_data[\"X_train_final\"].shape}')\n",
    "print(f'  Test features: {prep_data[\"X_test_final\"].shape}')\n",
    "print(f'  Feature dimensions: {prep_data[\"X_train_final\"].shape[1]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Multi-class SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multi-class SVM model\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    random_state=42,\n",
    "    probability=True,\n",
    "    class_weight='balanced',\n",
    "    decision_function_shape='ovr'  # One-vs-Rest for multi-class\n",
    ")\n",
    "\n",
    "print('Multi-class SVM Configuration:')\n",
    "print(f'  Kernel: {svm_model.kernel}')\n",
    "print(f'  C: {svm_model.C}')\n",
    "print(f'  Decision Function: {svm_model.decision_function_shape}')\n",
    "print(f'  Class Weight: {svm_model.class_weight}')\n",
    "print(f'  Number of classes: {len(np.unique(y_train))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(f'Training multi-class SVM on {FEATURE_METHOD.upper()} features...')\n",
    "print(f'Feature dimensions: {prep_data[\"X_train_final\"].shape}')\n",
    "print(f'Expected time: Varies by method (2-10 minutes)')\n",
    "\n",
    "start_time = time.time()\n",
    "svm_model.fit(prep_data['X_train_final'], y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f'\\n✓ Training complete! Time: {training_time:.2f} seconds ({training_time/60:.1f} minutes)')\n",
    "print(f'Number of support vectors per class: {svm_model.n_support_}')\n",
    "print(f'Total support vectors: {sum(svm_model.n_support_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = svm_model.predict(prep_data['X_train_final'])\n",
    "y_test_pred = svm_model.predict(prep_data['X_test_final'])\n",
    "y_test_proba = svm_model.predict_proba(prep_data['X_test_final'])\n",
    "\n",
    "print('✓ Predictions complete!')\n",
    "print(f'\\nSample predictions (first 10):')\n",
    "for i in range(10):\n",
    "    true_class = label_encoder.classes_[y_test[i]]\n",
    "    pred_class = label_encoder.classes_[y_test_pred[i]]\n",
    "    match = '✓' if y_test[i] == y_test_pred[i] else '✗'\n",
    "    prob = y_test_proba[i][y_test_pred[i]]\n",
    "    print(f'  {match} True: {true_class:6s} | Predicted: {pred_class:6s} | Prob: {prob:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "top2_accuracy = top_k_accuracy_score(y_test, y_test_proba, k=2)\n",
    "\n",
    "print('=' * 70)\n",
    "print(f'MULTI-CLASS CLASSIFICATION - {FEATURE_METHOD.upper()} FEATURES')\n",
    "print('=' * 70)\n",
    "print(f'\\nFeature Extraction:')\n",
    "print(f'  Method: {FEATURE_METHOD.upper()}')\n",
    "print(f'  Feature dimensions: {prep_data[\"X_train_final\"].shape[1]:,}')\n",
    "print(f'  Extraction time: {preprocessing_time:.2f} seconds')\n",
    "print(f'\\nPerformance:')\n",
    "print(f'  Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)')\n",
    "print(f'  Testing Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)')\n",
    "print(f'  Top-2 Accuracy:    {top2_accuracy:.4f} ({top2_accuracy*100:.2f}%)')\n",
    "print(f'  Random Baseline:   {1/7:.4f} ({100/7:.2f}%)')\n",
    "print(f'\\nTiming:')\n",
    "print(f'  Preprocessing time: {preprocessing_time:.2f} seconds')\n",
    "print(f'  Training time: {training_time:.2f} seconds ({training_time/60:.1f} minutes)')\n",
    "print(f'  Total time: {(preprocessing_time + training_time)/60:.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.title(f'Confusion Matrix - {FEATURE_METHOD.upper()} Features', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nInterpretation:')\n",
    "print('  - Diagonal: Correct predictions')\n",
    "print('  - Off-diagonal: Misclassifications')\n",
    "print('  - Look for: nv ↔ mel confusion (benign vs malignant)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix\n",
    "cm_normalized = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', cbar=True,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            vmin=0, vmax=1)\n",
    "plt.title(f'Normalized Confusion Matrix - {FEATURE_METHOD.upper()} Features', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Values show proportion of true class predicted as each class (row-wise normalization)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print('=' * 70)\n",
    "print('CLASSIFICATION REPORT')\n",
    "print('=' * 70)\n",
    "\n",
    "report = classification_report(\n",
    "    y_test,\n",
    "    y_test_pred,\n",
    "    target_names=class_names,\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Save classification report\n",
    "report_dict = classification_report(\n",
    "    y_test,\n",
    "    y_test_pred,\n",
    "    target_names=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "print('\\nPer-Class Performance Summary:')\n",
    "for i, class_name in enumerate(class_names):\n",
    "    support = (y_test == i).sum()\n",
    "    if class_name in report_df.index:\n",
    "        f1 = report_df.loc[class_name, 'f1-score']\n",
    "        recall = report_df.loc[class_name, 'recall']\n",
    "        full_name = DX_DICT[class_name]\n",
    "        print(f'  {class_name}: {full_name:30s} F1={f1:.3f}, Recall={recall:.3f} (n={support})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-class metrics\n",
    "metrics_df = report_df[report_df.index.isin(class_names)][['precision', 'recall', 'f1-score']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, metric in enumerate(['precision', 'recall', 'f1-score']):\n",
    "    axes[i].bar(range(len(class_names)), metrics_df[metric], color='steelblue')\n",
    "    axes[i].set_xticks(range(len(class_names)))\n",
    "    axes[i].set_xticklabels(class_names, rotation=45)\n",
    "    axes[i].set_ylabel(metric.capitalize(), fontsize=12)\n",
    "    axes[i].set_title(f'{metric.capitalize()} by Class', fontsize=13, fontweight='bold')\n",
    "    axes[i].set_ylim([0, 1])\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "    axes[i].axhline(y=metrics_df[metric].mean(), color='red', linestyle='--', \n",
    "                    label=f'Mean: {metrics_df[metric].mean():.3f}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.suptitle(f'Per-Class Performance Metrics - {FEATURE_METHOD.upper()}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and preprocessing artifacts\n",
    "save_dir = f'../models/{FEATURE_METHOD}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(f'../results/{FEATURE_METHOD}', exist_ok=True)\n",
    "\n",
    "# Save SVM model\n",
    "with open(f'{save_dir}/svm_multiclass_model_{FEATURE_METHOD}.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "\n",
    "# Save scaler\n",
    "with open(f'{save_dir}/scaler_multiclass_{FEATURE_METHOD}.pkl', 'wb') as f:\n",
    "    pickle.dump(prep_data['scaler'], f)\n",
    "\n",
    "# Save label encoder\n",
    "with open(f'{save_dir}/label_encoder_multiclass_{FEATURE_METHOD}.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'method': FEATURE_METHOD,\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'top2_accuracy': top2_accuracy,\n",
    "    'confusion_matrix': cm_test,\n",
    "    'preprocessing_time': preprocessing_time,\n",
    "    'training_time': training_time,\n",
    "    'feature_dim': prep_data['X_train_final'].shape[1],\n",
    "    'feature_params': FEATURE_PARAMS,\n",
    "    'class_names': class_names.tolist()\n",
    "}\n",
    "\n",
    "with open(f'{save_dir}/svm_multiclass_metrics_{FEATURE_METHOD}.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "\n",
    "# Save classification report\n",
    "report_df.to_csv(f'../results/{FEATURE_METHOD}/multiclass_classification_report_{FEATURE_METHOD}.csv')\n",
    "\n",
    "print('✓ Model and artifacts saved successfully!')\n",
    "print(f'\\nSaved files to: {save_dir}/')\n",
    "print(f'  - svm_multiclass_model_{FEATURE_METHOD}.pkl')\n",
    "print(f'  - scaler_multiclass_{FEATURE_METHOD}.pkl')\n",
    "print(f'  - label_encoder_multiclass_{FEATURE_METHOD}.pkl')\n",
    "print(f'  - svm_multiclass_metrics_{FEATURE_METHOD}.pkl')\n",
    "print(f'\\nResults saved to: ../results/{FEATURE_METHOD}/')\n",
    "print(f'  - multiclass_classification_report_{FEATURE_METHOD}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Results\n",
    "\n",
    "This notebook demonstrated multi-class feature extraction:\n",
    "\n",
    "**Method:** {FEATURE_METHOD.upper()}\n",
    "- ✓ 7 classes (nv, mel, bkl, bcc, akiec, vasc, df)\n",
    "- ✓ Test accuracy: {test_accuracy:.2%}\n",
    "- ✓ Top-2 accuracy: {top2_accuracy:.2%}\n",
    "- ✓ Training time: {training_time/60:.1f} minutes\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **Class Imbalance**: nv dominates (67%), rare classes struggle\n",
    "2. **Best Performance**: nv (dominant class) typically has highest F1-score\n",
    "3. **Challenging Classes**: df, vasc (<2% of data) hard to classify\n",
    "4. **Common Confusion**: nv ↔ mel (benign vs malignant nevi)\n",
    "\n",
    "### Feature Extraction Benefits\n",
    "\n",
    "**Why it works:**\n",
    "- Semantic features capture lesion patterns\n",
    "- Reduced dimensionality speeds training\n",
    "- Transfer learning (VGG16) leverages ImageNet\n",
    "- More robust to image variations\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try different methods**: Switch between HOG, VGG16, ResNet50\n",
    "2. **Address imbalance**: Try SMOTE, class weights, stratified sampling\n",
    "3. **Tune hyperparameters**: Adjust SVM C, gamma\n",
    "4. **Ensemble methods**: Combine multiple feature extractors\n",
    "5. **Deploy**: Use saved artifacts for inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
